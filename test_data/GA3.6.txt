ShopSmart is an online retail platform that places a high value on customer feedback. Each month, the company receives hundreds of comments from shoppers regarding product quality, delivery speed, customer service, and more. To automatically understand and cluster this feedback, ShopSmart's data science team uses text embeddings to capture the semantic meaning behind each comment.

As part of a pilot project, ShopSmart has curated a collection of 25 feedback phrases that represent a variety of customer sentiments. Examples of these phrases include comments like “Fast shipping and great service,” “Product quality could be improved,” “Excellent packaging,” and so on. Due to limited processing capacity during initial testing, you have been tasked with determine which pair(s) of 5 of these phrases are most similar to each other. This similarity analysis will help in grouping similar feedback to enhance the company’s understanding of recurring customer issues.

ShopSmart has written a Python program that has the 5 phrases and their embeddings as an array of floats. It looks like this:

embeddings = {"Fast shipping and great service.":[-0.1079404279589653,0.020684150978922844,-0.30074435472488403,0.11729881167411804,0.13952496647834778,-0.018052106723189354,-0.21843314170837402,0.13527116179466248,-0.09257353842258453,-0.09384968131780624,0.11293865740299225,-0.03900212049484253,-0.059287477284669876,-0.1008152961730957,-0.019155437126755714,-0.007078605704009533,-0.02967032417654991,0.03711449354887009,-0.18302017450332642,0.20056714117527008,0.09076566994190216,0.02584189549088478,0.0943814069032669,-0.03799184039235115,-0.25246360898017883,-0.1235731765627861,0.028952494263648987,-0.309251993894577,0.021375395357608795,-0.22204887866973877,0.2159872055053711,-0.11921302229166031,0.21928390860557556,-0.11432114243507385,0.017453914508223534,0.10065577924251556,-0.04200637340545654,0.17493793368339539,0.1322934925556183,0.17025874555110931,-0.15271177887916565,0.004682514350861311,0.2531017065048218,0.11580997705459595,0.014688937924802303,-0.11176885664463043,-0.292662113904953,-0.0397731214761734,0.13729171454906464,0.027570005506277084],"I am satisfied with my purchase.":[-0.020752977579832077,-0.09531638771295547,-0.3484536111354828,-0.1267419159412384,-0.0037368356715887785,-0.1731869876384735,0.05239512771368027,0.1812744438648224,0.020825186744332314,-0.17896373569965363,0.2537148892879486,-0.18543370068073273,-0.2016085982322693,-0.07076519727706909,0.3070920705795288,0.04739823937416077,-0.09860913455486298,-0.09826252609491348,0.007762508932501078,0.15215961635112762,0.11980980634689331,0.21616600453853607,0.16960540413856506,-0.050286613404750824,-0.14592072367668152,-0.14464983344078064,-0.08884642273187637,-0.12847493588924408,-0.14499644935131073,-0.18993955850601196,-0.0064482977613806725,-0.10750532895326614,0.05973160266876221,-0.3542303442955017,-0.11934766918420792,0.06377533078193665,-0.04237246513366699,-0.052886154502630234,0.02117179147899151,-0.10490579158067703,0.03414059802889824,0.07527106255292892,0.03232092037796974,0.005061877891421318,-0.0063363732770085335,0.06198453530669212,-0.13217206299304962,0.20276394486427307,-0.0804123729467392,0.05866290256381035],"Customer service resolved my issue quickly.":[-0.27243417501449585,-0.08034132421016693,-0.3335980772972107,0.03278002515435219,-0.0688093826174736,-0.11652996391057968,-0.13710907101631165,0.2432539016008377,0.07779283076524734,0.0949951708316803,0.1365993618965149,-0.05979407951235771,-0.17151375114917755,-0.040170662105083466,0.12054384499788284,0.10894818603992462,-0.1374913454055786,-0.008736561983823776,-0.2501348555088043,0.040648505091667175,0.20974119007587433,0.021232154220342636,0.1484498679637909,-0.07186757773160934,-0.26733720302581787,0.24248935282230377,-0.04475795477628708,-0.1304829716682434,-0.11914216727018356,-0.2516639530658722,0.16577963531017303,-0.1684555560350418,-0.08875136077404022,-0.1995472013950348,-0.10072928667068481,0.1209898293018341,0.11015872657299042,-0.053359128534793854,0.16705389320850372,0.0013867400120943785,-0.018269527703523636,0.014486604370176792,0.08320838212966919,0.06033563241362572,-0.07224985212087631,0.09869049489498138,-0.021837422624230385,0.1448819786310196,0.10996758937835693,0.058328691869974136],"The product did not meet my expectations.":[-0.0789492279291153,-0.017544273287057877,-0.20415154099464417,0.05229542776942253,-0.33714449405670166,-0.0982111245393753,0.12587708234786987,0.11225880682468414,-0.0027278736233711243,0.023417923599481583,-0.13826850056648254,-0.291504830121994,-0.18145440518856049,-0.02094884216785431,0.16108831763267517,0.11158403009176254,-0.012337733991444111,-0.12710395455360413,-0.3081902861595154,0.03130057826638222,0.03367764130234718,0.21053127944469452,-0.07563666999340057,-0.1394953727722168,-0.22488567233085632,0.02143959142267704,0.15299096703529358,-0.07631145417690277,0.011356235481798649,0.15188677608966827,0.042173732072114944,-0.1614563763141632,0.12152169644832611,-0.29862070083618164,0.09680021554231644,0.09864052385091782,0.11354702711105347,-0.026837829500436783,0.0004603167180903256,0.1484515368938446,0.014362072572112083,0.04327791556715965,-0.09661618620157242,0.026745814830064774,-0.12047885358333588,0.252981036901474,0.135446697473526,-0.1340971291065216,0.08907092362642288,-0.11428314447402954],"Product quality could be improved.":[0.02994030900299549,0.0700574517250061,-0.09608972817659378,0.0757998675107956,0.05681799724698067,-0.12199439853429794,0.1026616021990776,0.34097179770469666,0.10221496969461441,-0.022985607385635376,0.00909215584397316,-0.12154776602983475,-0.33331525325775146,-0.03502872586250305,0.09934376925230026,-0.07471518963575363,0.232376366853714,-0.1896272748708725,-0.17048589885234833,0.0928356945514679,0.21285215020179749,0.060550566762685776,0.17584548890590668,0.05365967005491257,0.0439932718873024,0.0900282934308052,0.18656465411186218,-0.18146029114723206,-0.006986604072153568,-0.11421024054288864,0.14624014496803284,-0.19919796288013458,0.14802667498588562,-0.062432803213596344,-0.26695844531059265,0.0347416065633297,0.3560296893119812,0.1255674511194229,0.022554926574230194,-0.060359153896570206,-0.0147787407040596,0.09608972817659378,0.043897565454244614,0.11484828591346741,0.15619367361068726,-0.04826818034052849,0.020592935383319855,-0.09813147783279419,0.06405982375144958,-0.08907122164964676]}
Your task is to write a Python function most_similar(embeddings) that will calculate the cosine similarity between each pair of these embeddings and return the pair that has the highest similarity. The result should be a tuple of the two phrases that are most similar.

Write your Python code here: